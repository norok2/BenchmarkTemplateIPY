{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "def benchmark(\n",
    "        funcs,\n",
    "        argss=None,\n",
    "        kwss=None,\n",
    "        input_sizes=(5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000),\n",
    "        gen_input=lambda n: [random.random() for _ in range(n)],\n",
    "        equal_output=lambda a, b: a == b,\n",
    "        store_all=False):\n",
    "    runtimes = np.zeros((3, len(input_sizes), len(funcs)))\n",
    "    labels = [func.__name__ for func in funcs]\n",
    "    if argss is None: argss = ()\n",
    "    if kwss is None: kwss = ()\n",
    "    results = [] if store_all else None\n",
    "    len_lbl = min(max(map(len, labels)), 20)\n",
    "    len_n = max(map(lambda x: int(np.ceil(np.log10(x))), input_sizes)) + 1\n",
    "    for i, input_size in enumerate(input_sizes):\n",
    "        input_data = gen_input(input_size)\n",
    "        truth = None\n",
    "        for j, (func, args, kws) in \\\n",
    "                enumerate(itertools.zip_longest(funcs, argss, kwss)):\n",
    "            args = tuple(args) if args is not None else ()\n",
    "            kws = dict(kws) if kws is not None else {}\n",
    "            result = func(input_data, *args, **kws)\n",
    "            if truth is None and j == 0:\n",
    "                truth = result\n",
    "            is_equal = 1.0 if equal_output(result, truth) else -1.0\n",
    "            print(':{lbl:<{len_lbl}s}  N={n!s:<{len_n}s} {eq:>4s}  '.format(\n",
    "                lbl=labels[j], n=input_size, eq='OK' if is_equal > 0 else 'FAIL',\n",
    "                len_lbl=len_lbl, len_n=len_n),\n",
    "                end='')\n",
    "            timing_result = %timeit -o func(input_data, *args, **kws)\n",
    "            if store_all:\n",
    "                results.append(result)\n",
    "            runtimes[:, i, j] = is_equal, timing_result.average, timing_result.stdev\n",
    "        print()\n",
    "    return runtimes, input_sizes, labels, results\n",
    "\n",
    "\n",
    "def plot_benchmarks(\n",
    "        runtimes,\n",
    "        input_sizes,\n",
    "        labels,\n",
    "        panels=('Small', 'Medium', 'Large'),\n",
    "        units='µs',\n",
    "        save_filepath='benchmarks.png',\n",
    "        dry=True):\n",
    "    num_panels = len(panels)\n",
    "    subplot_shape = 1, num_panels\n",
    "    fig, axs = plt.subplots(\n",
    "        *subplot_shape, squeeze=False, figsize=(16, 4))\n",
    "    if units == 'ms':\n",
    "        units_factor = 1e3\n",
    "    elif units == 'µs':\n",
    "        units_factor = 1e6\n",
    "    elif units == 'ns':\n",
    "        units_factor = 1e9\n",
    "    else:\n",
    "        units_factor = 1\n",
    "    for i, panel in enumerate(panels):\n",
    "        ij = np.unravel_index(i, subplot_shape)\n",
    "        plot_sizes = int(len(input_sizes) * ((i + 1) / num_panels))\n",
    "        axs[ij].set_title(panel)\n",
    "        axs[ij].set_xlabel('Input Sizes / #')\n",
    "        axs[ij].set_ylabel('Timings / ' + units)\n",
    "        for k, label in enumerate(labels):\n",
    "            x = input_sizes[:plot_sizes]\n",
    "            y = runtimes[1, :plot_sizes, k] * units_factor\n",
    "            dy = runtimes[2, :plot_sizes, k] * units_factor\n",
    "            axs[ij].plot(x, y, label=label)\n",
    "            axs[ij].fill_between(x, y - dy, y + dy, alpha=0.25)\n",
    "            axs[ij].legend()\n",
    "    if save_filepath and not dry:\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(save_filepath.replace(' ', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":f1  N=5        OK  404 ns ± 5.06 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      ":f2  N=5        OK  552 ns ± 14.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "\n",
      ":f1  N=10       OK  578 ns ± 36.9 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      ":f2  N=10       OK  822 ns ± 10.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "\n",
      ":f1  N=50       OK  1.77 µs ± 49 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      ":f2  N=50       OK  2.79 µs ± 19.2 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "\n",
      ":f1  N=100      OK  3.17 µs ± 63.9 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      ":f2  N=100      OK  5.28 µs ± 93.4 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "\n",
      ":f1  N=500      OK  15.1 µs ± 114 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      ":f2  N=500      OK  25.5 µs ± 605 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "\n",
      ":f1  N=1000     OK  29.2 µs ± 158 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      ":f2  N=1000     OK  49.1 µs ± 90.8 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "\n",
      ":f1  N=5000     OK  145 µs ± 1.91 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      ":f2  N=5000     OK  254 µs ± 1.48 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "\n",
      ":f1  N=10000    OK  289 µs ± 3.78 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      ":f2  N=10000    OK  514 µs ± 5.54 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "\n",
      ":f1  N=50000    OK  1.46 ms ± 38 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      ":f2  N=50000    OK  2.79 ms ± 122 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n",
      ":f1  N=100000   OK  2.97 ms ± 99.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      ":f2  N=100000   OK  "
     ]
    }
   ],
   "source": [
    "def f1(items):\n",
    "    return [item * item for item in items]\n",
    "\n",
    "\n",
    "def f2(items):\n",
    "    return [item ** 2 for item in items]\n",
    "\n",
    "\n",
    "def gen_input(n):\n",
    "    return [random.random() for _ in range(n)]\n",
    "\n",
    "\n",
    "def equal_output(a, b):\n",
    "    return a == b\n",
    "\n",
    "\n",
    "input_sizes = (5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000)  \n",
    "# input_sizes = (5, 10, 50, 100, 500, 1000, 5000)  # for n² problems\n",
    "funcs = f1, f2\n",
    "\n",
    "\n",
    "runtimes, input_sizes, labels, results = benchmark(\n",
    "    funcs, gen_input=gen_input, equal_output=equal_output,\n",
    "    input_sizes=input_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_benchmarks(runtimes, input_sizes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
